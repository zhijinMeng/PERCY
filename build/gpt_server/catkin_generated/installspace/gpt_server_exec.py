#!/usr/bin/env python3

import rospy
from gpt_server.srv import GPTGenerate, GPTGenerateRequest, GPTGenerateResponse


from transformers import GPT2LMHeadModel, GPT2Tokenizer


class GPT:
    """
    ChatGPT server class.
    This will run in the background, waiting for a request to be made.
    GPT server accepts a string as request and outputs a string generated by chatGPT.
    """

    def __init__(self):
        rospy.init_node('gpt_server')
        self.service = rospy.Service('gpt_generate', GPTGenerate, self.OnRequest)

        rospy.loginfo('GPT node started')

        #Here, initialise ChatGPT 3
        self.model = GPT2LMHeadModel.from_pretrained('gpt2')
        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')




    def OnRequest(self, data:GPTGenerateRequest):
        input_text = data.request   # Speech recognised by user

        # Here, return a string generated by ChatGPT on input_text (string)

        input_ids = self.tokenizer.encode(input_text, return_tensors='pt')
        output = self.get_model.generate(input_ids, max_length=50, num_beams=5, no_repeat_ngram_size = 2)

        return self.tokenizer.decode(output[0], skip_special_tokens=True)
        
        
if __name__ == '__main__':
    gpt = GPT()
    rospy.spin()